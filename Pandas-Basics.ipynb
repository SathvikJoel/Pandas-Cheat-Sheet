{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 : Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* s.values\n",
    "* s.index\n",
    "* s.dtype\n",
    "* s.is_unique ( is every value unique )\n",
    "* s.name\n",
    "* s.size\n",
    "* s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* s.sum()\n",
    "* s.mean()\n",
    "* s.product()\n",
    "* s.medain()\n",
    "* s.mode()\n",
    "* s.describe()\n",
    "--------------\n",
    "* s.sort_values()\n",
    "* s.head()\n",
    "* s.tail()\n",
    "* s.sort_index()\n",
    "* s.get(keys , default = None)\n",
    "* s[\"a\" : \"b\"]\n",
    "* s.count() \n",
    "  *  excludes NaN values\n",
    "* s.idxmax() \n",
    "  *  index position that has the smallest value\n",
    "* s.idxmin() \n",
    "  *  index position that has the largets value\n",
    "* s.value_counts()\n",
    "  *  Takes all the values and tells how many times each value appers\n",
    "  *  important method\n",
    "*  s.apply(fxn)\n",
    "   *  apply a method all the values of the series\n",
    "*  s.map(series_2) \n",
    "   *  maps values of s to indices of series_2 and returns a new series "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pokemon\n",
       "Bulbasaur    Grass\n",
       "Ivysaur      Grass\n",
       "Venusaur     Grass\n",
       "Name: Type, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon_types = pd.read_csv(\"pandas/pokemon.csv\", index_col=\"Pokemon\", squeeze=True)\n",
    "pokemon_types.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Bulbasaur\n",
       "1      Ivysaur\n",
       "2     Venusaur\n",
       "Name: Pokemon, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon_names =  pd.read_csv(\"pandas/pokemon.csv\", usecols=[\"Pokemon\"], squeeze=True)\n",
    "pokemon_names.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Grass\n",
       "1    Grass\n",
       "2    Grass\n",
       "Name: Pokemon, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon_names.map(pokemon_types).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2 : Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Whenever a column has NaN values the values in that columns is stored as floating point numbers\n",
    "----\n",
    "* df.head()\n",
    "* df.tail()\n",
    "* df.describe()\n",
    "* df.info()\n",
    "* df.index\n",
    "* df.values\n",
    "* df.shape\n",
    "* df.dtype\n",
    "* df.columns\n",
    "* df.axes\n",
    "----\n",
    "* df.sum(axis = 1/0)\n",
    "* Extract a column from df\n",
    "  - df[\"Name\"]\n",
    "* Extract Two or more Columns from a df\n",
    "  * df[[\"Name\", \"Number\", \"Position\"]]\n",
    "* Add new Column to df\n",
    "  * df[\"sport\"] = \"Basketball\"\n",
    "  * df[\"sport\"] = some_series\n",
    "  * df.insert(pos, column = \"sport\", value = \"Basketball\")\n",
    "  * df.insert(pos, column = \"sport\", value = maybe a series)\n",
    "  \n",
    "* Broadcasting Operations\n",
    "  * df[\"Age\"] + 5\n",
    "  * df[\"Age\"] - 5\n",
    "  * df[\"Age\"] * 5\n",
    "* Review of `value_counts`\n",
    "  * It is available only for series\n",
    "  * extraxt a series and do `value_counts`\n",
    "* drop NaN values\n",
    "  * df.dropna(inplace = True)\n",
    "  * by default any row having NaN will be removed\n",
    "  * You can change this way using **how** parameter\n",
    "  * df.dropna(**axis = 1**), any columns having NaN values are dropped\n",
    "  * df.dropna( **subset = [\"Salary\"]**), only if NaN is in salary column that particular row is dropped else it is not dropped\n",
    "* Fill in Null Values with `.fillna()` Method\n",
    "  * direct df.fillna(0) doesnt make sense all the time\n",
    "  * Call on each series indivudually\n",
    "  * df[\"Salary\"].fillna(0, inplace = True)\n",
    "  * df[\"College\"].fillna(\"No College\", inplace = True)\n",
    "* The `.astype()` Method\n",
    "  * Remove all the NaN values\n",
    "  * df[\"Salary\"].astype(\"int\")\n",
    "  * df[\"College\"].astype(\"String\")\n",
    "* `category` data type in Pandas\n",
    "  * df[\"Position\"].astype(\"category\")\n",
    "  * If the unique values are very less in number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sort_values` on df\n",
    "    * df.sort_values(\"Name\", ascending = True)\n",
    "    * Change the NaN position bu using **na_position** parameter\n",
    "    \n",
    "* `sort_values` on multiple columns\n",
    "    * df.sort_values([\"name\", \"Salary\"], ascending = [True, False])\n",
    "    \n",
    "* `sort_index`\n",
    "    * df.sort_index( ascending = True , inplace  = True)\n",
    "\n",
    "* `rank()` Method on Series\n",
    "    * Remove Null values\n",
    "    * df[\"Salary\"].rank(ascending = False).astype(\"int\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 3 : Filtering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pd.to_datetime( df[\"Start Date\"] )\n",
    "    * pass a series to chnage it to the datetime type\n",
    "\n",
    "\n",
    "* Initially when a Dataset is presented first change the types of columns appropriately for the furthur operations to go smooth\n",
    "\n",
    "\n",
    "* Instead of manual date time change you can use **parse_dates** parameter in `read_csv()`\n",
    "\n",
    "\n",
    "##### Filter Based on a Condition\n",
    "\n",
    "* df[\"Gender\"] == \"Male\" returns a boolean series\n",
    "\n",
    "* To extract the rows following a condition pass the boolean series to df\n",
    "    * df[ df[\"Gender\"] == \"Male\" ]\n",
    "   \n",
    "   \n",
    "* More than one condition\n",
    "    * df[( df[\"Gender\"] == Male ) & ( df[\"Salary\"] > 1000000 ) ]\n",
    "    * df[( df[\"Gender\"] == Male ) |  ( df[\"Salary\"] > 1000000 ) ]\n",
    "    \n",
    "    \n",
    "* `isin()` Method\n",
    "    * It optimizes the above process\n",
    "    * df[\"Team\"].isin([\"Marketing\", \"Legal\"]) returns a boolean series whenever the column has Marketing ot Legal\n",
    "  \n",
    "  \n",
    "* `.isnull()` and `.notnull()` Methods\n",
    "    * df[\"Team\"].isnull() returns a boolean series\n",
    "    * df[\"Team\"].notnull() returns a boolean series\n",
    "   \n",
    "   \n",
    "* `.between()` between lower bound and upper bound\n",
    "    * df[\"Salary\"].between(60000,700000) returns a boolean series\n",
    "    * can take dates, times, floats\n",
    "        \n",
    "\n",
    "* `.duplicated()` -> boolean array on a series\n",
    "    * df[\"First Name\"].duplicated( keep = 'last'/ 'first'/ False)\n",
    "    * False implies all the duplicates are cosidered duplictes\n",
    " \n",
    " \n",
    "* `drop_duplicates()`  applicable on a DF\n",
    "    * by default drops only rows that are completely the same\n",
    "    * df.drop_duplicates( subsets , keep ) \n",
    "    \n",
    "    \n",
    "* `.unique()` and `nunique()` on a series\n",
    "    * gives unique values -> `.unique()`\n",
    "    * gives number of unique values -> `.nunique()`\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 3 : Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `set_index()` and `reset_index()`\n",
    "    * df.set_index( keys = \"Film\" ) , makes Film column the index\n",
    "    * df.reset_index(), back to the numerical indexing\n",
    "    * you can drop the exisiting index using **drop**\n",
    "    \n",
    "    \n",
    "* Retrive Rows using `.loc[]` \n",
    "    * df.loc[\"A index name\"]\n",
    "    * Remember Indexes could be the same ( no problem )\n",
    "    * supports list slicing, df.loc[\"Diamonds Are Foreevr\": \"Saccred Eye\"]\n",
    "    * Right end point is included\n",
    "    * All the python slicing methods works\n",
    "    \n",
    "    \n",
    "* Retrieve Rows using index location\n",
    "    * df.iloc[1:5]\n",
    "    * df.iloc[1:15:3]\n",
    "\n",
    "\n",
    "* second Arguments to `loc` and `iloc`\n",
    "    * df.loc[\"Arow_name\", \"Acol_name\"]\n",
    "    * df.loc[\"Arow_name\", [\"a1col\", \"a2col\"]]\n",
    "    * you can slice in the both the indices\n",
    "    * same things apply for **iloc**\n",
    "   \n",
    "   \n",
    "* Set a new value for a specific cell\n",
    "    * df.loc[\"Hello\",\"bye\"] = \"Something\"\n",
    "    * df.loc[\"A\", [\"B\", \"C\"]] = a list\n",
    "\n",
    "\n",
    "\n",
    "* Set Multiple Values in DataFrame\n",
    "    * When you do df[df[\"A\"] == b] this creates a new dataframe altogether and is not the original dataframe\n",
    "    * df.loc[mask] this doesnt create a new dataframe rather this is just a slice from original dataframe\n",
    "    * df.loc[mask, \"A\"] = anything\n",
    "    * This is the correct method\n",
    "   \n",
    "   \n",
    "\n",
    "\n",
    "* Remame Index labels or Column Labels\n",
    "    * df.remane(mapper = dict, axis = 0), dict is a mapping function.\n",
    "    * df.remane( index = dict ), same dict\n",
    "    * df.rename( columns = dict ), same dict\n",
    "    * for a bulk remane use, df.columns = [list]\n",
    "    * for a bulk remane use, df.rows = [list]\n",
    "    \n",
    "    \n",
    "    \n",
    "* delete Rows or columns in a Dataframe\n",
    "    * df.drop( labels , axis )\n",
    "        * labels are the row indices\n",
    "        * axis is the rows/columns\n",
    "     * df.pop(\"Actor\"), returns the Actor Col and also removes it from the dataframe\n",
    "     * del df[\"Director\"]\n",
    "     \n",
    "\n",
    "* Create Random Sample\n",
    "    * df.sample(n = 5), returns a random row\n",
    "        * n rows are returned\n",
    "        * frac is the percentage of \n",
    "        * axis = 0/1\n",
    "      \n",
    "      \n",
    "* `.nsmallest()` and `.nlargest()`\n",
    "    * df.nlargest(3, columns = \"Box Office\")\n",
    "    * df.nsmallest(3 , columns = \"Box Office\")\n",
    "\n",
    "\n",
    "* Filtering with `.where()` method\n",
    "    * df.where(mask), it returns the whole df but keeps NaN in all the rows where the row is not filtered\n",
    "    \n",
    "\n",
    "* Filtering with `.query()` Method\n",
    "    * For this to work the columns names should not have spaces\n",
    "    * but this looks very wierd I dont want to use it\n",
    "  \n",
    " \n",
    "* Apply Method with Row Values\n",
    "    * create a function fxn(row) , this takes each row as a argument and gives a value\n",
    "    * df.apply(fxn, axis = 'columns'), the columns here is a little bit confusing just read up Documentation\n",
    "\n",
    "\n",
    "\n",
    "* Create a copy of DataFrame with `.copy()`\n",
    "    * directors[\"A View to kill\"] this is chuck of origianl dataframe and effects the original\n",
    "    * df.copy()\n",
    "    * df[\"Director\"].copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 5 : Working Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Common String Methods\n",
    "    * `.lower()` \n",
    "    * `.upper()`\n",
    "    * `.title()` -> first char of each word is captilized and all others are made lower\n",
    "    * `len()`\n",
    "    *  when called on a column the syntax is as follows\n",
    "    * df[\"A\"].str.lower()\n",
    "    * str prefic must be given before using the method\n",
    "    * df[\"A\"].str.upper()\n",
    "    * df[\"A\"].str.title()\n",
    "\n",
    "\n",
    "* `.str().replace()`\n",
    "    * \"Hello World\".replace(\"l\",\"!\") -> replaces all the instances of l with !\n",
    "    * df[\"D\"].str.replace(\"MANGT\", \"Management\")\n",
    "    * df[\"A\"].str.replace(\",\",\"\")\n",
    "    \n",
    "    \n",
    "* Filtering with String Method\n",
    "    * df[\"A\"].str.contains(\"Hello\") -> returns true if it contains the substring\n",
    "    * df[\"A\"].str.startswith(\"Hello\") -> only starts with Hello\n",
    "    * df[\"A\"].str.endswith(\"Hello\") -> only ends with Hello\n",
    "\n",
    "\n",
    "* `strip()` & `lstirip()` & `rstrip()`\n",
    "    * removes whitespaces from beggining, last, or both accordingly\n",
    "    * df[\"A\"].str.lstritp()\n",
    "    * df[\"B\"].str.rstrip()\n",
    "    \n",
    "    \n",
    "* String methods on Index and Columns\n",
    "    * df.index.str.strip().str.title()\n",
    "\n",
    "\n",
    "* `.split()`\n",
    "    * \"Hello my name is Boris\".split(\" \") -> ['Hello', 'my','name','is','Boris']\n",
    "    * df[\"A\"].str.split(\",\")\n",
    "    * df[\"A\"].str.split(\",\").str.get(0) -> gets 1st element from each list\n",
    "    * **get** and **split** are complementaory\n",
    "   \n",
    " \n",
    "* `.split()`\n",
    "    * **expand** parameter generates a dataframe rather than a series\n",
    "    * **n** parameter determins maximum number of splits we can do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 6 : Multi Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use set_index and pass it a index to get multi index\n",
    "    * Use the column with least unique values to be the outer most level\n",
    "    * The order in the array  effects the indexing\n",
    "    * sort_indices sorts each layer\n",
    "    * df.index returns array of tuples\n",
    "    * so we need two ids to idexntify a value\n",
    "    \n",
    "* `get_level_index()` \n",
    "    * df.index.get_level_index(0) returns the index values at that level. \n",
    "\n",
    "\n",
    "* Change the names of the indexes\n",
    "    * df.index.set_names(names , Level , inplace ) \n",
    "    * names is a list or a label\n",
    "    * Level is the level which you want to change\n",
    "\n",
    "\n",
    "* `sort_index()`\n",
    "    * You can sort each level or only a single level using the appropriate parameters\n",
    "    * But when the higher levels are individually sorted the grouping by lower levels will not remian intact\n",
    "    \n",
    "    \n",
    "* Extract Rows from MultiIndex\n",
    "        * important\n",
    "        \n",
    "    * Remeber `.loc` for normal dfs, the first argument is a row index and the second index is a column index\n",
    "    * The same syntax is preferred here\n",
    "    * So the first index must be a tuple( not list ) of required multiIndex and second index must be a label or a list of column names\n",
    "    * There is not such problem with `iloc` accessor\n",
    "    * Every row is given a unique index number wrt row\n",
    "    \n",
    "    \n",
    "* Remember that there could be multiIndex in Columns as well as in Rows. So all of this appleis to column multi index as well. \n",
    "\n",
    "\n",
    "* Each of the entries in `loc` accessor must be a tuple when dealing with multi Indices\n",
    "\n",
    "\n",
    "* `swaplevel`\n",
    "    * df.swaplevel() swaps levels \n",
    "    \n",
    "* `stack()` \n",
    "    * Takes the column values and makes them into index values\n",
    "    \n",
    "\n",
    "* `to_frame()` \n",
    "    * converts series into dataframe\n",
    "    \n",
    "    \n",
    "* `unstack()`\n",
    "    * Takes the index and makes it into a column\n",
    "    * You can use a combination of stack and unstack to methods to get the shape you want\n",
    "    * you can pass in arguments to say which layer should be unstacked outer most layer is 0th layer\n",
    "    * inner most layer is -1\n",
    "    * you can also pass in a list to move multiple layers at once\n",
    "    * you can use **fill_na** parameter to fill in the NaN values\n",
    "    \n",
    "   \n",
    "* `pivot()`\n",
    "    * you can align/ condense along the common values\n",
    "    * practice this for more efficieny\n",
    "    * choose the index values , column values and values which needs to be at their intersection\n",
    "    \n",
    "    \n",
    "* `pivot_table()` method\n",
    "    * you can aggregate on a column based on a different column grouping\n",
    "    * very impotant method\n",
    "    \n",
    "    \n",
    "* `pd.melt()`\n",
    "     * opposite of melt\n",
    "     * all the indxes are melted into a single row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Salesman</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Bob</td>\n",
       "      <td>7172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>Bob</td>\n",
       "      <td>6362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>Bob</td>\n",
       "      <td>5982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Salesman  Revenue\n",
       "0 2016-01-01      Bob     7172\n",
       "1 2016-01-02      Bob     6362\n",
       "2 2016-01-03      Bob     5982"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pivot Table Illustration\n",
    "df  = pd.read_csv(\"pandas/salesmen.csv\" , parse_dates=[\"Date\"])\n",
    "df[\"Salesman\"] = df[\"Salesman\"].astype(\"category\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Salesman</th>\n",
       "      <th>Bob</th>\n",
       "      <th>Dave</th>\n",
       "      <th>Jeb</th>\n",
       "      <th>Oscar</th>\n",
       "      <th>Ronald</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>7172</td>\n",
       "      <td>1864</td>\n",
       "      <td>4430</td>\n",
       "      <td>5250</td>\n",
       "      <td>2639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>6362</td>\n",
       "      <td>8278</td>\n",
       "      <td>8026</td>\n",
       "      <td>8661</td>\n",
       "      <td>4951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>5982</td>\n",
       "      <td>4226</td>\n",
       "      <td>5188</td>\n",
       "      <td>7075</td>\n",
       "      <td>2703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>7917</td>\n",
       "      <td>3868</td>\n",
       "      <td>3144</td>\n",
       "      <td>2524</td>\n",
       "      <td>4258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>7837</td>\n",
       "      <td>2287</td>\n",
       "      <td>938</td>\n",
       "      <td>2793</td>\n",
       "      <td>7771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-27</th>\n",
       "      <td>2045</td>\n",
       "      <td>2843</td>\n",
       "      <td>6666</td>\n",
       "      <td>835</td>\n",
       "      <td>2981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>100</td>\n",
       "      <td>8888</td>\n",
       "      <td>1243</td>\n",
       "      <td>3073</td>\n",
       "      <td>6129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-29</th>\n",
       "      <td>4115</td>\n",
       "      <td>9490</td>\n",
       "      <td>3498</td>\n",
       "      <td>6424</td>\n",
       "      <td>7662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30</th>\n",
       "      <td>2577</td>\n",
       "      <td>3594</td>\n",
       "      <td>8858</td>\n",
       "      <td>7088</td>\n",
       "      <td>2570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>3845</td>\n",
       "      <td>6830</td>\n",
       "      <td>9717</td>\n",
       "      <td>8408</td>\n",
       "      <td>2619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Salesman     Bob  Dave   Jeb  Oscar  Ronald\n",
       "Date                                       \n",
       "2016-01-01  7172  1864  4430   5250    2639\n",
       "2016-01-02  6362  8278  8026   8661    4951\n",
       "2016-01-03  5982  4226  5188   7075    2703\n",
       "2016-01-04  7917  3868  3144   2524    4258\n",
       "2016-01-05  7837  2287   938   2793    7771\n",
       "...          ...   ...   ...    ...     ...\n",
       "2016-12-27  2045  2843  6666    835    2981\n",
       "2016-12-28   100  8888  1243   3073    6129\n",
       "2016-12-29  4115  9490  3498   6424    7662\n",
       "2016-12-30  2577  3594  8858   7088    2570\n",
       "2016-12-31  3845  6830  9717   8408    2619\n",
       "\n",
       "[366 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot(index = \"Date\" , columns= \"Salesman\" , values=\"Revenue\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>City</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Item</th>\n",
       "      <th>Spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wanda</td>\n",
       "      <td>Female</td>\n",
       "      <td>Stamford</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Burger</td>\n",
       "      <td>15.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eric</td>\n",
       "      <td>Male</td>\n",
       "      <td>Stamford</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Chalupa</td>\n",
       "      <td>10.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charles</td>\n",
       "      <td>Male</td>\n",
       "      <td>New York</td>\n",
       "      <td>Never</td>\n",
       "      <td>Sushi</td>\n",
       "      <td>42.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anna</td>\n",
       "      <td>Female</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Once</td>\n",
       "      <td>Ice Cream</td>\n",
       "      <td>11.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deborah</td>\n",
       "      <td>Female</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Chalupa</td>\n",
       "      <td>23.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First Name  Gender          City Frequency       Item  Spend\n",
       "0      Wanda  Female      Stamford    Weekly     Burger  15.66\n",
       "1       Eric    Male      Stamford     Daily    Chalupa  10.56\n",
       "2    Charles    Male      New York     Never      Sushi  42.14\n",
       "3       Anna  Female  Philadelphia      Once  Ice Cream  11.01\n",
       "4    Deborah  Female  Philadelphia     Daily    Chalupa  23.49"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pivot Table Illustration\n",
    "food = pd.read_csv(\"pandas/foods.csv\")\n",
    "food.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>New York</th>\n",
       "      <th>Philadelphia</th>\n",
       "      <th>Stamford</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th>Item</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Female</th>\n",
       "      <th>Burger</th>\n",
       "      <td>51.626667</td>\n",
       "      <td>52.878710</td>\n",
       "      <td>45.037778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burrito</th>\n",
       "      <td>42.563043</td>\n",
       "      <td>52.098571</td>\n",
       "      <td>53.532647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chalupa</th>\n",
       "      <td>46.135789</td>\n",
       "      <td>52.291562</td>\n",
       "      <td>64.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donut</th>\n",
       "      <td>46.670323</td>\n",
       "      <td>54.642000</td>\n",
       "      <td>48.734118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ice Cream</th>\n",
       "      <td>56.356296</td>\n",
       "      <td>46.225625</td>\n",
       "      <td>46.910455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sushi</th>\n",
       "      <td>47.751290</td>\n",
       "      <td>58.096000</td>\n",
       "      <td>45.622188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Male</th>\n",
       "      <th>Burger</th>\n",
       "      <td>58.822273</td>\n",
       "      <td>44.675238</td>\n",
       "      <td>46.424516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burrito</th>\n",
       "      <td>55.976000</td>\n",
       "      <td>43.764333</td>\n",
       "      <td>46.438929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chalupa</th>\n",
       "      <td>49.110800</td>\n",
       "      <td>48.444783</td>\n",
       "      <td>50.011304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donut</th>\n",
       "      <td>44.842333</td>\n",
       "      <td>37.859394</td>\n",
       "      <td>49.004483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ice Cream</th>\n",
       "      <td>55.297586</td>\n",
       "      <td>53.445610</td>\n",
       "      <td>42.368800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sushi</th>\n",
       "      <td>51.709259</td>\n",
       "      <td>49.852857</td>\n",
       "      <td>70.434444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "City               New York  Philadelphia   Stamford\n",
       "Gender Item                                         \n",
       "Female Burger     51.626667     52.878710  45.037778\n",
       "       Burrito    42.563043     52.098571  53.532647\n",
       "       Chalupa    46.135789     52.291562  64.094000\n",
       "       Donut      46.670323     54.642000  48.734118\n",
       "       Ice Cream  56.356296     46.225625  46.910455\n",
       "       Sushi      47.751290     58.096000  45.622188\n",
       "Male   Burger     58.822273     44.675238  46.424516\n",
       "       Burrito    55.976000     43.764333  46.438929\n",
       "       Chalupa    49.110800     48.444783  50.011304\n",
       "       Donut      44.842333     37.859394  49.004483\n",
       "       Ice Cream  55.297586     53.445610  42.368800\n",
       "       Sushi      51.709259     49.852857  70.434444"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food.pivot_table(values = \"Spend\", index = [\"Gender\",\"Item\"], columns=\"City\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 7 : Groupby "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ideal thing to groupby is the column having less unique values\n",
    "\n",
    "\n",
    "* df.groupby(\"Sector\")\n",
    "    * It creates a lot of smaller data frames that are created by using the column Sector \n",
    "   \n",
    "   \n",
    "* len(groupby_obj) -> number of groups. Each corresponding to a unique value of the coumn\n",
    "\n",
    "\n",
    "* `sectors.size()` -> number of rows in each group\n",
    "    * it is similar to value counts() method\n",
    "\n",
    "* `sectors.first()` -> extracts first row of each group\n",
    "\n",
    "\n",
    "* `sectors.last()` -> extracts last row of each group\n",
    "\n",
    "\n",
    "* `sectors.groups` -> returns a dictionary, keys are unique value, values are list of index values corresponding to orginal dataframe\n",
    "\n",
    "\n",
    "* Retrieve a group using `get_group()`\n",
    "    * sectors.get_group(\"Energy\") -> gives a dataframe that has Energy in sector column\n",
    "    \n",
    "    \n",
    "* `sectors.max()` -> from each group it gives the max of each group on the last column\n",
    "\n",
    "\n",
    "* `sectors.sum()` -> gives sum across each column of every group\n",
    "\n",
    "\n",
    "* `sectors.mean()` -> gives mean across each column of every group\n",
    "\n",
    "\n",
    "* `sectors[\"Revenue\"].sum()` -> gives sum across only Revenue column ( rather than the whole group )\n",
    "\n",
    "\n",
    "* Grouping by multiple columns\n",
    "    * d.groupby([\"A\"], [\"B\"] )\n",
    "    * it is grouped by first A and then by B\n",
    "    \n",
    "    \n",
    "* `.agg()`\n",
    "   * sectors.agg(dict)\n",
    "   * dict has column names as key and aggregates as values\n",
    "   * you can also apply multiple operations to different columns by using list\n",
    "\n",
    "\n",
    "* Iterate through all the groups \n",
    "    * \n",
    "    ```\n",
    "    for sector.data in sectors()\n",
    "        df.append(data.nlargest(1, \"Revenue\"))\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
